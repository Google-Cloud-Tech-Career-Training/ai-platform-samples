{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/notebook_template.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial walks through building a custom container to serve a scikit-learn model on AI Platform Predictions. You will use the FastAPI Python web server framework to create a prediction and health endpoint.\n",
        "You will also cover incorporating a pre-processor from training into your online serving.\n",
        "\n",
        "\n",
        "### Dataset\n",
        "\n",
        "This tutorial uses R.A. Fisher's Iris dataset, a small dataset that is popular for trying out machine learning techniques. Each instance has four numerical features, which are different measurements of a flower, and a target label that\n",
        "marks it as one of three types of iris: Iris setosa, Iris versicolour, or Iris virginica.\n",
        "\n",
        "This tutorial uses [the copy of the Iris dataset included in the\n",
        "scikit-learn library](https://scikit-learn.org/stable/datasets/index.html#iris-dataset).\n",
        "\n",
        "### Objective\n",
        "\n",
        "The goal is to:\n",
        "- Train a model that uses a flower's measurements as input to predict what type of iris it is.\n",
        "- Save the model and its serialized pre-processor\n",
        "- Build a FastAPI server to handle predictions and health checks\n",
        "- Build a custom container with model artifacts\n",
        "- Upload and deploy custom container to AI Platform Prediction\n",
        "\n",
        "This tutorial focuses more on deploying this model with AI Platform than on\n",
        "the design of the model itself.\n",
        "\n",
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* AI Platform (Unified)\n",
        "\n",
        "Learn about [AI Platform (Unified)\n",
        "pricing](https://cloud.google.com/ai-platform-unified/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4-nDLfK4pw"
      },
      "source": [
        "### Set up your local development environment\n",
        "\n",
        "**If you are using Colab or AI Platform Notebooks**, your environment already meets\n",
        "all the requirements to run this notebook. You can skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCuSR8GkAgzl"
      },
      "source": [
        "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
        "You need the following:\n",
        "\n",
        "* Docker\n",
        "* Git\n",
        "* Google Cloud SDK (gcloud)\n",
        "* Python 3\n",
        "* virtualenv\n",
        "* Jupyter notebook running in a virtual environment with Python 3\n",
        "\n",
        "The Google Cloud guide to [Setting up a Python development\n",
        "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
        "installation guide](https://jupyter.org/install) provide detailed instructions\n",
        "for meeting these requirements. The following steps provide a condensed set of\n",
        "instructions:\n",
        "\n",
        "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
        "\n",
        "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
        "\n",
        "1. [Install\n",
        "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
        "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
        "\n",
        "1. To install Jupyter, run `pip install jupyter` on the\n",
        "command-line in a terminal shell.\n",
        "\n",
        "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
        "\n",
        "1. Open this notebook in the Jupyter Notebook Dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "Install additional package dependencies not installed in your notebook environment, such as NumPy, Scikit-learn, FastAPI, Uvicorn, and joblib. Use the latest major GA version of each package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "joblib~=1.0\n",
        "numpy~=1.20\n",
        "scikit-learn~=0.24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyy5Lbnzg5fi"
      },
      "outputs": [],
      "source": [
        "# Required in Docker serving container\n",
        "%pip install -U -r requirements.txt --user\n",
        "\n",
        "# For local FastAPI development and running\n",
        "%pip install -U \"uvicorn[standard]>=0.12.0,<0.14.0\" fastapi~=0.63 --user\n",
        "\n",
        "# AI Platform (Unified) SDK\n",
        "%pip install -U google-cloud-aiplatform --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the AI Platform (Unified) API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component). {TODO: Update the APIs needed for your tutorial. Edit the API names, and update the link to append the API IDs, separating each one with a comma. For example, container.googleapis.com,cloudbuild.googleapis.com}\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "# Get your Google Cloud project ID from gcloud\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "PROJECT = shell_output[0]\n",
        "print(\"Project ID: \", PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYoRfYng0XZ"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "outputs": [],
      "source": [
        "if PROJECT == \"\" or PROJECT is None:\n",
        "    PROJECT = \"PROJECT_ID\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr--iN2kAylZ"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "**If you are using AI Platform Notebooks**, your environment is already\n",
        "authenticated. Skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "**If you are using Colab**, run the cell below and follow the instructions\n",
        "when prompted to authenticate your account via oAuth.\n",
        "\n",
        "**Otherwise**, follow these steps:\n",
        "\n",
        "1. In the Cloud Console, go to the [**Create service account key**\n",
        "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
        "\n",
        "2. Click **Create service account**.\n",
        "\n",
        "3. In the **Service account name** field, enter a name, and\n",
        "   click **Create**.\n",
        "\n",
        "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"AI Platform\"\n",
        "into the filter box, and select\n",
        "   **AI Platform Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "5. Click *Create*. A JSON file that contains your key downloads to your\n",
        "local environment.\n",
        "\n",
        "6. Enter the path to your service account key as the\n",
        "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "# If on AI Platform, then don't execute this code\n",
        "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\") and not os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Configure project and naming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "REPOSITORY = \"custom-container-prediction-sklearn\"  # @param {type:\"string\"}\n",
        "IMAGE = \"sklearn-fastapi-server\"  # @param {type:\"string\"}\n",
        "MODEL_DISPLAY_NAME = \"sklearn_custom_container\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%mkdir app"
      ]
    },
    {
      "source": [
        "## Write your pre-processor\n",
        "Scaling training data so each numerical feature column has a mean of 0 and a standard deviation of 1 [can improve your model](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data).\n",
        "\n",
        "Create `preprocess.py`, which contains a class to do this scaling:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile app/preprocess.py\n",
        "import numpy as np\n",
        "\n",
        "class MySimpleScaler(object):\n",
        "    def __init__(self):\n",
        "        self._means = None\n",
        "        self._stds = None\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        if self._means is None:  # during training only\n",
        "            self._means = np.mean(data, axis=0)\n",
        "\n",
        "        if self._stds is None:  # during training only\n",
        "            self._stds = np.std(data, axis=0)\n",
        "            if not self._stds.all():\n",
        "                raise ValueError(\"At least one column has standard deviation of 0.\")\n",
        "\n",
        "        return (data - self._means) / self._stds\n"
      ]
    },
    {
      "source": [
        "## Train and store model with pre-processor\n",
        "Next, use `preprocess.MySimpleScaler` to preprocess the iris data, then train a model using scikit-learn.\n",
        "\n",
        "At the end, export your trained model as a joblib (`.joblib`) file and export your `MySimpleScaler` instance as a pickle (`.pkl`) file:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd app/\n",
        "\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from preprocess import MySimpleScaler\n",
        "\n",
        "iris = load_iris()\n",
        "scaler = MySimpleScaler()\n",
        "\n",
        "X = scaler.preprocess(iris.data)\n",
        "y = iris.target\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "joblib.dump(model, \"model.joblib\")\n",
        "with open (\"preprocessor.pkl\", \"wb\") as f:\n",
        "  pickle.dump(scaler, f)\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "source": [
        "## Build a FastAPI server"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile app/main.py\n",
        "from fastapi import FastAPI, Request\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from preprocess import MySimpleScaler\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "with open(\"preprocessor.pkl\", \"rb\") as f:\n",
        "    preprocessor = pickle.load(f)\n",
        "\n",
        "_class_names = load_iris().target_names\n",
        "_model = joblib.load(\"model.joblib\")\n",
        "_preprocessor = preprocessor\n",
        "\n",
        "\n",
        "@app.get(\"/health\", status_code=200)\n",
        "def health():\n",
        "    return {}\n",
        "\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(request: Request):\n",
        "    body = await request.json()\n",
        "\n",
        "    instances = body[\"instances\"]\n",
        "    inputs = np.asarray(instances)\n",
        "    preprocessed_inputs = _preprocessor.preprocess(inputs)\n",
        "    outputs = _model.predict(preprocessed_inputs)\n",
        "\n",
        "    return {\"predictions\": [_class_names[class_num] for class_num in outputs]}\n"
      ]
    },
    {
      "source": [
        "### Store test instances to use later\n",
        "To learn more about formatting input instances in JSON, [read the documentation.](https://cloud.google.com/ai-platform-unified/docs/predictions/online-predictions-custom-models#request-body-details)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile instances.json\n",
        "{\n",
        "    \"instances\": [\n",
        "        [6.7, 3.1, 4.7, 1.5],\n",
        "        [4.6, 3.1, 1.5, 0.2]\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "source": [
        "## Build and push container to Artifact Registry"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Build your container"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
        "\n",
        "COPY ./app /app\n",
        "COPY requirements.txt requirements.txt\n",
        "\n",
        "RUN pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker build \\\n",
        "    --tag={REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE} \\\n",
        "    ."
      ]
    },
    {
      "source": [
        "### Run and test the container locally (optional)\n",
        "\n",
        "Run the container locally in detached mode and test the `/health` and `/predict` routes. Afterwards, stop the running image."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker run -d -p 80:80 \\\n",
        "    --name=local-iris \\\n",
        "    {REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl localhost/health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "  -d @instances.json \\\n",
        "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "  localhost/predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker stop local-iris"
      ]
    },
    {
      "source": [
        "### Push the container to artifact registry\n",
        "\n",
        "Configure Docker to access Artifact Registry. Then push your container image to your Artifact Registry repository."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud beta artifacts repositories create {REPOSITORY} \\\n",
        " --repository-format=docker \\\n",
        " --location=$REGION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud auth configure-docker {REGION}-docker.pkg.dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker push {REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE}"
      ]
    },
    {
      "source": [
        "## Deploy to AI Platform (Unified)\n",
        "\n",
        "Use the Python SDK to upload and deploy your model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Upload the custom container model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT, location=REGION)"
      ]
    },
    {
      "source": [
        "model = aiplatform.Model.upload(\n",
        "  display_name=MODEL_DISPLAY_NAME,\n",
        "  serving_container_image_uri=f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE}\",\n",
        "  serving_container_ports=[80],\n",
        "  serving_container_health_route=\"/health\",\n",
        "  serving_container_predict_route=\"/predict\",\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "### Deploy the model on AI Platform (Unified)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
      ]
    },
    {
      "source": [
        "## Send predictions\n",
        "\n",
        "### Using Python SDK"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint.predict(\n",
        "    instances=[\n",
        "        [6.7, 3.1, 4.7, 1.5],\n",
        "        [4.6, 3.1, 1.5, 0.2]\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "source": [
        "### Using REST"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ENDPOINT_ID = endpoint.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl \\\n",
        "    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "    -H \"Content-Type: application/json\" \\\n",
        "    -d @instances.json \\\n",
        "    https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT}/locations/{REGION}/endpoints/{ENDPOINT_ID}:predict"
      ]
    },
    {
      "source": [
        "### Using gcloud CLI"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud beta ai endpoints predict $ENDPOINT_ID \\\n",
        "  --region=$REGION \\\n",
        "  --json-request=instances.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete the model resource\n",
        "model.delete()\n",
        "\n",
        "# Delete the container image from Artifact Registry\n",
        "!gcloud artifacts docker images delete \\\n",
        "    --quiet \\\n",
        "    --delete-tags \\\n",
        "    {REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "notebook_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python380jvsc74a57bd08166a0749a42b4f71c753ec8cc0362bfd3cb56240a34df05ff6aa6beec75d681",
      "display_name": "Python 3.8.0 64-bit"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}